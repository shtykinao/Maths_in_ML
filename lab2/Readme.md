## Лабораторная работа № 2
## Использование численных методов в задачах оптимизации 
**Цель работы** - реализовать современные методы оптимизации с использованием численных методов дифференцирования для решения прикладных задач.

Ход работы: 
- Были реализованы алгоритмы оптимизации BFGS и L-BFGS, в которых используется как аналитическое 
$\bigr($для функции $f(x) = \frac{1}{2} \left[(x_1)^2 + \sum_{i=1}^{2} (x_i - x_{i+1})^2 + (x_3)^2 \right] - x_1 \bigl)$, так и численное (на основе конечных разностей) задание градиента;
-  Реализован алгоритм оптимизации Adam, адаптированный под конечно-разностные методы определения производных;
- На основе реализованных методов оптимизации была обучена простая перцептронная нейронная сеть;
- Был проведен сравнительный анализ работы алгоритмов BFGS, L-BFGS и Adam при решении задачи классификации вина ([см. lab1](https://github.com/shtykinao/Maths_in_ML/tree/main/lab1)).

Результаты: 

Алгоритм оптимизации Adam показал наилучшую точность. L-BFGS продемонстрировал немного меньшую точность, но при этом сходился быстрее, чем Adam и BFGS. BFGS показал себя наименее эффективным в данной задаче, достигнув наименьшей точности и требуя больше времени на обучение. 